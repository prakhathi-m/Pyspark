{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import ArrayType,StringType,DoubleType,IntegerType\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYihMfc6B5T3"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-a6e611c80d06>:1 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a6e611c80d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m~/spark-2.4.0-bin-hadoop2.7/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    312\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 314\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-2-a6e611c80d06>:1 "
     ]
    }
   ],
   "source": [
    "sc=pyspark.SparkContext()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NO5wgyUHCBpI"
   },
   "outputs": [],
   "source": [
    "spark= SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"PART 1\") \\\n",
    "        .config(\"spark.some.config.option\",\"15g\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "9O00z_dMCDm6",
    "outputId": "02dae5a6-6eda-4e2f-a74c-040dd1f7ca72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               genre|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "|23890098|          Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|\n",
      "|31186339|    The Hunger Games|The nation of Pan...|['Action/Adventur...|\n",
      "|20663735|          Narasimham|Poovalli Induchoo...|['Musical', 'Acti...|\n",
      "| 2231378|  The Lemon Drop Kid|The Lemon Drop Ki...|          ['Comedy']|\n",
      "|  595909|   A Cry in the Dark|Seventh-day Adven...|['Crime Fiction',...|\n",
      "| 5272176|            End Game|The president is ...|['Action/Adventur...|\n",
      "| 1952976|          Dark Water|{{plot}} The film...|['Thriller', 'Dra...|\n",
      "|24225279|                Sing|The story begins ...|           ['Drama']|\n",
      "| 2462689|       Meet John Doe|Infuriated at bei...|['Black-and-white...|\n",
      "|20532852|Destination Meatball|A line of people ...|['Animation', 'Sh...|\n",
      "|15401493|    Husband for Hire|Lola  attempts to...|          ['Comedy']|\n",
      "|18188932|         Up and Down|Milan and Goran a...|['Crime Fiction',...|\n",
      "| 2940516|Ghost In The Noon...|Bumbling pirate c...|          ['Comedy']|\n",
      "| 1480747|       House Party 2|{{plot}} Followin...|          ['Comedy']|\n",
      "|24448645|Forest of the Dam...|Despite Lucy's re...|          ['Horror']|\n",
      "|15072401|Charlie Chan's Se...|Alan Colby, heir ...|['Crime Fiction',...|\n",
      "| 4018288|     The Biggest Fan|Debbie's favorite...|           ['Drama']|\n",
      "| 4596602|      Ashes to Ashes|Ashes to Ashes is...|['Crime Fiction',...|\n",
      "|15224586|        Green Dragon|The film follows ...|  ['Indie', 'Drama']|\n",
      "|15585766|  The Rats of Tobruk|Three friends are...|           ['Drama']|\n",
      "+--------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df = spark.read.load(\"sample-movie-train.csv\",format=\"csv\", sep=\",\",inferSchema='true', header='true')\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "p_df = pd.read_csv(\"train.csv\")\n",
    "# print(p_df)\n",
    "sqlCtx = SQLContext(sc)\n",
    "df = sqlCtx.createDataFrame(p_df)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "3zVjVmig0yJ1",
    "outputId": "83538b03-2982-479b-ac0c-5cb5cd0feff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "# print(p_df)\n",
    "sqlCtx = SQLContext(sc)\n",
    "test = sqlCtx.createDataFrame(test)\n",
    "test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBJpATdAXRVi"
   },
   "outputs": [],
   "source": [
    "df_map = spark.read.load(\"mapping.csv\",format=\"csv\", sep=\",\",inferSchema='true', header='true')\n",
    "dd_map= df_map.select(\"0\").collect()[:]\n",
    "\n",
    "def map_gen(x):\n",
    "    output_array=[]\n",
    "    for gen in dd_map:\n",
    "        if gen[0] in x:\n",
    "            output_array.append(1)\n",
    "        else:\n",
    "            output_array.append(0)\n",
    "    return output_array\n",
    "             \n",
    "mapper = udf(map_gen,ArrayType(IntegerType()))\n",
    "genre_mapped = df.withColumn(\"mapped_genre\", mapper(\"genre\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "lMntfa95XaoL",
    "outputId": "cf6a517a-6744-4910-8f84-4ac1a07743cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               genre|        mapped_genre|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "|23890098|          Taxi Blues|Shlykov, a hard-w...|['World cinema', ...|[1, 0, 0, 0, 0, 1...|\n",
      "|31186339|    The Hunger Games|The nation of Pan...|['Action/Adventur...|[1, 0, 0, 0, 1, 0...|\n",
      "|20663735|          Narasimham|Poovalli Induchoo...|['Musical', 'Acti...|[1, 0, 0, 0, 1, 0...|\n",
      "| 2231378|  The Lemon Drop Kid|The Lemon Drop Ki...|          ['Comedy']|[0, 1, 0, 0, 0, 0...|\n",
      "|  595909|   A Cry in the Dark|Seventh-day Adven...|['Crime Fiction',...|[1, 0, 0, 0, 0, 1...|\n",
      "| 5272176|            End Game|The president is ...|['Action/Adventur...|[1, 0, 0, 1, 1, 0...|\n",
      "| 1952976|          Dark Water|{{plot}} The film...|['Thriller', 'Dra...|[1, 0, 0, 1, 0, 0...|\n",
      "|24225279|                Sing|The story begins ...|           ['Drama']|[1, 0, 0, 0, 0, 0...|\n",
      "| 2462689|       Meet John Doe|Infuriated at bei...|['Black-and-white...|[1, 1, 1, 0, 0, 0...|\n",
      "|20532852|Destination Meatball|A line of people ...|['Animation', 'Sh...|[0, 0, 0, 0, 0, 0...|\n",
      "|15401493|    Husband for Hire|Lola  attempts to...|          ['Comedy']|[0, 1, 0, 0, 0, 0...|\n",
      "|18188932|         Up and Down|Milan and Goran a...|['Crime Fiction',...|[1, 1, 0, 0, 0, 1...|\n",
      "| 2940516|Ghost In The Noon...|Bumbling pirate c...|          ['Comedy']|[0, 1, 0, 0, 0, 0...|\n",
      "| 1480747|       House Party 2|{{plot}} Followin...|          ['Comedy']|[0, 1, 0, 0, 0, 0...|\n",
      "|24448645|Forest of the Dam...|Despite Lucy's re...|          ['Horror']|[0, 0, 0, 0, 0, 0...|\n",
      "|15072401|Charlie Chan's Se...|Alan Colby, heir ...|['Crime Fiction',...|[0, 0, 0, 1, 0, 0...|\n",
      "| 4018288|     The Biggest Fan|Debbie's favorite...|           ['Drama']|[1, 0, 0, 0, 0, 0...|\n",
      "| 4596602|      Ashes to Ashes|Ashes to Ashes is...|['Crime Fiction',...|[0, 0, 1, 1, 1, 0...|\n",
      "|15224586|        Green Dragon|The film follows ...|  ['Indie', 'Drama']|[1, 0, 0, 0, 0, 0...|\n",
      "|15585766|  The Rats of Tobruk|Three friends are...|           ['Drama']|[1, 0, 0, 0, 0, 0...|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre_mapped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "PMOGVNGEXgxF",
    "outputId": "93701e00-3a1e-4534-fb65-ebf3cf4caa98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- mapped_genre: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- label_0: integer (nullable = true)\n",
      " |-- label_1: integer (nullable = true)\n",
      " |-- label_2: integer (nullable = true)\n",
      " |-- label_3: integer (nullable = true)\n",
      " |-- label_4: integer (nullable = true)\n",
      " |-- label_5: integer (nullable = true)\n",
      " |-- label_6: integer (nullable = true)\n",
      " |-- label_7: integer (nullable = true)\n",
      " |-- label_8: integer (nullable = true)\n",
      " |-- label_9: integer (nullable = true)\n",
      " |-- label_10: integer (nullable = true)\n",
      " |-- label_11: integer (nullable = true)\n",
      " |-- label_12: integer (nullable = true)\n",
      " |-- label_13: integer (nullable = true)\n",
      " |-- label_14: integer (nullable = true)\n",
      " |-- label_15: integer (nullable = true)\n",
      " |-- label_16: integer (nullable = true)\n",
      " |-- label_17: integer (nullable = true)\n",
      " |-- label_18: integer (nullable = true)\n",
      " |-- label_19: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_label = len(dd_map)\n",
    "result = genre_mapped.select(['movie_id', 'movie_name', 'plot', 'genre', 'mapped_genre']+[expr('mapped_genre[' + str(x) + ']') for x in range(0, num_label)])\n",
    "\n",
    "new_colnames = ['movie_id', 'movie_name', 'plot', 'genre', 'mapped_genre'] + ['label_' + str(i) for i in range(0, num_label)] \n",
    "result = result.toDF(*new_colnames)\n",
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "id": "yyfJJ0GNJ7gL",
    "outputId": "93ed14ee-c66d-4ea9-f04d-6c355fcd89cb"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, Tokenizer, RegexTokenizer, StopWordsRemover, CountVectorizer, Word2Vec, PCA\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "w2v = Word2Vec(inputCol=\"words\", outputCol=\"features\")\n",
    "preprocessor = Pipeline(stages=[regexTokenizer, w2v ])\n",
    "model = preprocessor.fit(result)\n",
    "train = model.transform(result)\n",
    "\n",
    "model = preprocessor.fit(test)\n",
    "test = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "LdHvc9l2UFEG",
    "outputId": "f30e370f-b661-4079-a8ff-45e3bc444efc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- mapped_genre: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- label_0: integer (nullable = true)\n",
      " |-- label_1: integer (nullable = true)\n",
      " |-- label_2: integer (nullable = true)\n",
      " |-- label_3: integer (nullable = true)\n",
      " |-- label_4: integer (nullable = true)\n",
      " |-- label_5: integer (nullable = true)\n",
      " |-- label_6: integer (nullable = true)\n",
      " |-- label_7: integer (nullable = true)\n",
      " |-- label_8: integer (nullable = true)\n",
      " |-- label_9: integer (nullable = true)\n",
      " |-- label_10: integer (nullable = true)\n",
      " |-- label_11: integer (nullable = true)\n",
      " |-- label_12: integer (nullable = true)\n",
      " |-- label_13: integer (nullable = true)\n",
      " |-- label_14: integer (nullable = true)\n",
      " |-- label_15: integer (nullable = true)\n",
      " |-- label_16: integer (nullable = true)\n",
      " |-- label_17: integer (nullable = true)\n",
      " |-- label_18: integer (nullable = true)\n",
      " |-- label_19: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- movie_name: string (nullable = true)\n",
      " |-- plot: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()\n",
    "test.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "zvsblh2vX7Fy",
    "outputId": "1277ef1f-3500-4b17-f0f6-8a61be9c7aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_0\n",
      "label_1\n",
      "label_2\n",
      "label_3\n",
      "label_4\n",
      "label_5\n",
      "label_6\n",
      "label_7\n",
      "label_8\n",
      "label_9\n",
      "label_10\n",
      "label_11\n",
      "label_12\n",
      "label_13\n",
      "label_14\n",
      "label_15\n",
      "label_16\n",
      "label_17\n",
      "label_18\n",
      "label_19\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "\n",
    "# Model 1\n",
    "output = []\n",
    "models=[]\n",
    "for i in range(num_label):\n",
    "  label = \"label_\"+str(i)\n",
    "  print(label)\n",
    "  cur_train = train.select(\"movie_id\", \"movie_name\", \"features\", label)\n",
    "  lr = LogisticRegression(maxIter=1000,featuresCol=\"features\", labelCol=label)\n",
    "  model = lr.fit(cur_train)\n",
    "  models.append(model)\n",
    "\n",
    "  prediction = model.transform(test)\n",
    "\n",
    "  # prediction.show(5)\n",
    "  res = prediction.select('movie_id', 'prediction').collect()\n",
    "  output.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "f4CeMWZ5_RAB",
    "outputId": "563e2c0b-fd60-4500-f107-536c8d8f2371"
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "op_dic = defaultdict(list)\n",
    "for row in output:\n",
    "  for i in row:\n",
    "    op_dic[i[\"movie_id\"]].append(i['prediction'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7GsnVFjcIFOe",
    "outputId": "4f9282b4-16a1-41eb-9265-4dd6ad780950"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import csv\n",
    "with open('part3.csv', 'w') as f:\n",
    "    f.write(\"%s,%s\\n\"%('movie_id', 'predictions'))\n",
    "    for key in op_dic.keys():\n",
    "        f.write(\"%s,%s\\n\"%(key, ' '.join(str(e)[0] for e in op_dic[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=0\n",
    "for model in models:\n",
    "  model.save(\"part3_genre_\"+str(num)+\"_model\")\n",
    "  num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbL8_NteXgZA"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "num=0\n",
    "out=[]\n",
    "for i in range(num_label):\n",
    "  lr= LogisticRegressionModel.load(\"part3_genre_\"+str(num)+\"_model\")\n",
    "  num+=1\n",
    "  prediction = model.transform(test)\n",
    "  res = prediction.select('movie_id', 'prediction').collect()\n",
    "  out.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "op_dic = defaultdict(list)\n",
    "for row in output:\n",
    "  for i in row:\n",
    "    op_dic[i[\"movie_id\"]].append(i['prediction'])\n",
    "    \n",
    "\n",
    "\n",
    "import csv\n",
    "with open('part3.csv', 'w') as f:\n",
    "    f.write(\"%s,%s\\n\"%('movie_id', 'predictions'))\n",
    "    for key in op_dic.keys():\n",
    "        f.write(\"%s,%s\\n\"%(key, ' '.join(str(e)[0] for e in op_dic[key])))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of movie-pred-pyspark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
